{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals.joblib import Parallel, parallel_backend, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "audio_dir = os.path.expanduser('~/Desktop/university/AAU/1/sound-morphing/data/borisdrums')\n",
    "ann_path = os.path.expanduser('~/syncdir/datasets/borisdrums/annotation.csv')\n",
    "output_dir = os.path.expanduser('~/syncdir/datasets/borisdrums/spectrograms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read annotations\n",
    "df = pd.read_csv(ann_path, engine='python')\n",
    "filenames =  [\"{}.wav\".format(filename) for filename in df['filename'].values]\n",
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad or truncate a sequence data to a fixed length.\n",
    "def pad_trunc_seq(x, max_len):\n",
    "    \"\"\"\n",
    "    :param x: ndarray, The input sequence data\n",
    "    :param max_len: int, length of sequence to be padded or truncated\n",
    "    :return: ndarray, Padded or truncated input sequence data.\n",
    "    \"\"\"\n",
    "\n",
    "    l = len(x)\n",
    "    shape = x.shape\n",
    "    if l < max_len:\n",
    "        pad_shape = (max_len - l,) + shape[1:]\n",
    "        pad = np.zeros(pad_shape)\n",
    "        x_new = np.concatenate((x, pad), axis=0)\n",
    "    else:\n",
    "        x_new = x[0:max_len]\n",
    "\n",
    "    return x_new\n",
    "\n",
    "# generate single spectrum\n",
    "# set STFT parameters here!\n",
    "def extract_spectrum(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "    y = pad_trunc_seq(y, 16000)\n",
    "    s = librosa.core.stft(y, n_fft=1024, hop_length=512, window='hann', pad_mode='reflect')\n",
    "    return s\n",
    "\n",
    "# stores single spectrum\n",
    "def write_data(entry, audio_dir, output_dir):\n",
    "    output_path = os.path.join(output_dir, \"{}.npy\".format(entry['filename']))\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        file_path = os.path.join(audio_dir, \"{}.wav\".format(entry['filename']))\n",
    "        spectrum = extract_spectrum(file_path)\n",
    "        np.save(output_path, spectrum)\n",
    "        \n",
    "# generate all the spectra using parallel jobs\n",
    "def extract_spectra(df, audio_dir, output_dir):\n",
    "    with parallel_backend('threading'):\n",
    "        Parallel(n_jobs=-1, verbose=4)(\n",
    "            delayed(write_data)(entry, audio_dir, output_dir) for index, entry in df.iterrows())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the outcome\n",
    "for index, entry in df.iterrows():\n",
    "    write_data(entry, audio_dir, output_dir)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5505 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6264 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7073 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8837 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9270 out of 9270 | elapsed: 59.2min finished\n"
     ]
    }
   ],
   "source": [
    "# gogogo!\n",
    "extract_spectra(df, audio_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kick-open-1620Pearl-Vel87', 'kick-hit-1624Gretsch-Vel73',\n",
       "       'kick-hit-1426LudwigMuff-Vel68', ...,\n",
       "       'snare-center-Ayotte513-Vel119',\n",
       "       'hihat-ClosedEdge-ZildanBosphorus-Vel67',\n",
       "       'snare-center-Lingnum814-Vel73'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
