{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising test\n",
    "\n",
    "This script does the same as the denoise command (`denoise.py`):\n",
    " - load audio file\n",
    " - processes it (noise, stft, pre-proc, fragments, normalization)\n",
    " - load a trained model\n",
    " - predict clean speach\n",
    " - unprocess it\n",
    "\n",
    "On top of that, it allows the user to investigate individual fragments, quickly try different parameters, plot and listen to stuff, etc.   \n",
    "It's useful for testing trained model, especially while they're being trained!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/christie/miniconda3/envs/denoising/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import librosa as lr\n",
    "import librosa.display as lrd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from libs.utilities import load_autoencoder_lossfunc, load_autoencoder_model\n",
    "from libs.processing import pink_noise, take_file_as_noise, \\\n",
    "    make_fragments, unmake_fragments_slice , unmake_fragments,\\\n",
    "    s_to_exp, exp_to_s, s_to_reim, reim_to_s,\\\n",
    "    normalize_spectrum, normalize_spectrum_clean, unnormalize_spectrum  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_file = 'train'\n",
    "type_noise = 'pink'\n",
    "snr = 15\n",
    "model_path = '/data/riccardo_models/denoising/phase1/phase1bis_s_to_exp(0.167)_1.h5' # model_tcn2k3n8d2drop00_e4 model_tcnk3n8d2_Apr24_e407\n",
    "expo = 1.0/6\n",
    "proc_func, unproc_func = s_to_reim, reim_to_s # s_to_exp(expo), exp_to_s(expo)  #\n",
    "\n",
    "time_slice_ind = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURATION ###\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'#'0,1,2,3,4'\n",
    "\n",
    "if type_file == 'train':\n",
    "    input_path = '/data/riccardo_datasets/npr_news/ds0/train/NPR_News__03-15-2018_11PM_ET.wav'\n",
    "else:  # test\n",
    "    input_path = '/data/riccardo_datasets/npr_news/test/NPR_News__03-25-2018_11PM_ET.wav'\n",
    "\n",
    "model_name = 'model_example'\n",
    "sr = 16000\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "win_length = 512\n",
    "frag_win_length = 32\n",
    "p_time_slice_args = [0, 0.1, 0.5, 1]\n",
    "frag_hop_length = np.int(frag_win_length * p_time_slice_args[time_slice_ind]) if p_time_slice_args[time_slice_ind]!=0 else 1\n",
    "\n",
    "time_slice_args = [slice(np.int(frag_win_length//2-p/2*frag_win_length),\\\n",
    "                         np.int(frag_win_length//2+p/2*frag_win_length)) if p!=0 \\\n",
    "                   else slice(np.int(frag_win_length//2), np.int(frag_win_length//2)+1) \\\n",
    "                   for p in p_time_slice_args ]\n",
    "\n",
    "batch_size = 128\n",
    "normalize = False\n",
    "noisefile = '/data/riccardo_datasets/demand/NFIELD/ch01.wav' #NFIELD STRAFFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_time_slice_args[time_slice_ind]\n",
    "frag_hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dn] Loading data from /data/riccardo_datasets/npr_news/ds0/train/NPR_News__03-15-2018_11PM_ET.wav...\n",
      "[dn] Generated 3720 fragments with shape (257, 32)\n"
     ]
    }
   ],
   "source": [
    "### INPUT PROCESSING ###\n",
    "\n",
    "print('[dn] Loading data from {}...'.format(input_path))\n",
    "# load data from file name\n",
    "x, _ = lr.load(input_path, sr=sr, duration=30, offset=2)\n",
    "\n",
    "# apply noise!\n",
    "if type_noise == 'pink':\n",
    "    x_noisy = pink_noise(x=x, sr=sr, snr=snr)\n",
    "else:\n",
    "    x_noisy = take_file_as_noise(noisefile)(x=x, sr=sr, snr=snr)\n",
    "\n",
    "# convert to TF-domain\n",
    "s = lr.stft(x_noisy, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "# make fragments\n",
    "s_frags_noisy = make_fragments(s, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length)\n",
    "print('[dn] Generated {} fragments with shape {}'.format(len(s_frags_noisy), s_frags_noisy[0].shape))\n",
    "\n",
    "\n",
    "# apply pre-processing (data representation)\n",
    "y_frags_noisy = proc_func(s_frags_noisy)\n",
    "\n",
    "# normalize fragments\n",
    "y_frags_noisy_n = np.empty((y_frags_noisy.shape))\n",
    "std_frags_noisy = np.empty((len(y_frags_noisy),2))\n",
    "nf_frags_noisy = np.empty((len(y_frags_noisy),2))\n",
    "for i in range(len(y_frags_noisy)):\n",
    "    frag_normalized, frag_norm_factors = normalize_spectrum(y_frags_noisy[i])\n",
    "    y_frags_noisy_n[i] = frag_normalized if normalize else y_frags_noisy[i]\n",
    "nf_frags_noisy[i] = frag_norm_factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dn] Loading model from /data/riccardo_models/denoising/phase1/phase1bis_s_to_exp(0.167)_1.h5...\n",
      "[u] Loading autoencoder model from /data/riccardo_models/denoising/phase1/phase1bis_s_to_exp(0.167)_1.h5\n"
     ]
    }
   ],
   "source": [
    "#### LOAD TRAINED MODEL ###\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "# model_path = '/data/riccardo_models/denoising/model_tcnk3n8d2_Apr24_e407.h5' # model_tcn2k3n8d2drop00_e4\n",
    "#model_tcn2k3n2d8drop0_Apr25_e131.h5'\n",
    "\n",
    "\n",
    "\n",
    "time_slice = time_slice_args[time_slice_ind]# frag_win_length // 2 #\n",
    "\n",
    "print('[dn] Loading model from {}...'.format(model_path))\n",
    "model, lossfunc = load_autoencoder_model(model_path, time_slice = time_slice)\n",
    "# print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dn] Predicting with trained model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_1 to have shape (None, 256, 32, 1) but got array with shape (3720, 256, 32, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6285e1d4dffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[dn] Predicting with trained model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_frags_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_frags_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[dn] Prediction finished! Generated {} fragments'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_frags_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1694\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_1 to have shape (None, 256, 32, 1) but got array with shape (3720, 256, 32, 2)"
     ]
    }
   ],
   "source": [
    "### PREDICT DATA ###\n",
    "\n",
    "print('[dn] Predicting with trained model...')\n",
    "y_frags_pred = model.predict(y_frags_noisy)\n",
    "print('[dn] Prediction finished! Generated {} fragments'.format(len(y_frags_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT A FEW PREDICTED FRAGMENTS ###\n",
    "specrange = np.linspace(0, len(y_frags_pred), 10, dtype=int)\n",
    "print(list(specrange))\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "rangespan = len(specrange)\n",
    "j = 1\n",
    "y_frags_pred_dn = np.empty((y_frags_pred.shape))\n",
    "for i in range(len(y_frags_pred)):\n",
    "    # un-normalize (individually)\n",
    "    y_frags_pred_dn[i] = unnormalize_spectrum(y_frags_pred[i], nf_frags_noisy[i]) if normalize else y_frags_pred[i]\n",
    "    if i in specrange:        \n",
    "        plt.subplot(2,rangespan,j)\n",
    "        lrd.specshow(lr.amplitude_to_db(y_frags_noisy_n[i,...,0]), vmin=-10, vmax=5, cmap='coolwarm')\n",
    "        \n",
    "        plt.subplot(2,rangespan,rangespan+j)\n",
    "        lrd.specshow(lr.amplitude_to_db(y_frags_pred[i,...,0]), vmin=-10, vmax=5, cmap='coolwarm')\n",
    "        \n",
    "        j += 1\n",
    "        lrd.specshow(lr.power_to_db(np.abs(y_frags_pred[i,...,0])), cmap='coolwarm')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNPROCESS PREDICTED DATA ###\n",
    "\n",
    "# clip negative data\n",
    "#y_frags_pred_dn[y_frags_pred_dn<0]=0\n",
    "\n",
    "# invert data repr : #with or without phase: with or without \", s_frags_noisy\"\n",
    "s_pred = unproc_func(y_frags_pred_dn, s_frags_noisy)\n",
    "# s_pred = exp_to_s(1.0/6)(y_frags_pred) \n",
    "\n",
    "# undo fragments\n",
    "# s_pred = unmake_fragments(s_pred, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length)\n",
    "s_pred = unmake_fragments_slice(s_pred, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length, time_slice=time_slice)\n",
    "\n",
    "# get waveform\n",
    "x_pred = lr.istft(s_pred, hop_length=hop_length, win_length=win_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT RESULT AND LISTEN ###\n",
    "l = lr.time_to_frames(5, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(211)\n",
    "lrd.specshow(lr.amplitude_to_db(np.abs(s[:,:l])), vmin=-50, vmax=25, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.subplot(212)\n",
    "lrd.specshow(lr.amplitude_to_db(np.abs(s_pred[:,:l])), vmin=-50, vmax=25, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(x_pred, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGINAL AUDIO ###\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOISY AUDIO ###\n",
    "ipd.Audio(x_noisy, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT HISTOGRAMS ###\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.suptitle('Histograms (linear X scale, log Y scale)')\n",
    "\n",
    "## normalized\n",
    "bins = np.linspace(0, 2, 100) #np.logspace(-6, 2, 50)\n",
    "\n",
    "plt.subplot(221)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy_n.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Normalized true (network input)')\n",
    "\n",
    "plt.subplot(222)\n",
    "counts, bins, bars = plt.hist(y_frags_pred.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Normalized pred (network output)')\n",
    "\n",
    "## denormalized\n",
    "bins = np.linspace(0, 2, 100) #np.logspace(-6, 2, 50)\n",
    "\n",
    "plt.subplot(223)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('True (before processing)')\n",
    "\n",
    "plt.subplot(224)\n",
    "counts, bins, bars = plt.hist(y_frags_pred_dn.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Pred (after processing)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT HISTOGRAMS (LOG SCALE) ###\n",
    "bins = np.logspace(-1, 1, 100)\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.suptitle('Histograms (log X scale, linear Y scale)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "# normalized\n",
    "plt.subplot(221)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy_n.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Normalized true (network input)')\n",
    "\n",
    "plt.subplot(222)\n",
    "counts, bins, bars = plt.hist(y_frags_pred.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Normalized pred (network output)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "# denormalized\n",
    "plt.subplot(223)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('True (before processing)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "plt.subplot(224)\n",
    "counts, bins, bars = plt.hist(y_frags_pred_dn.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Pred (after processing)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WASTELANDS FROM HERE FORTH ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_frags_noisy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(np.abs(s), np.abs(s_pred))\n",
    "#print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.square(np.abs((y_frags_noisy[...,0]-y_frags_pred[...,0])[...,frag_win_length//2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_frags_noisy.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "\n",
    "x = np.linspace(0,0,128*32) + np.abs(np.random.randn(128*32) * 0.01)\n",
    "f1 = np.reshape(x, (128, 32))\n",
    "plt.subplot(221)\n",
    "lrd.specshow(f1, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f1: mean={:.2f} std={:.2f}'.format(f1.mean(), f1.std()))\n",
    "\n",
    "f2 = np.copy(f1)\n",
    "x = np.abs(np.random.randn(128*16) )\n",
    "f2[:,16:] += np.reshape(x, (128, 16))\n",
    "plt.subplot(222)\n",
    "lrd.specshow(f2, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f2: mean={:.2f} std={:.2f}'.format(f2.mean(), f2.std()))\n",
    "\n",
    "_, norm_factors = normalize_spectrum(np.concatenate([f1, f2], axis=1))\n",
    "f1_n = normalize_spectrum_clean(f1, norm_factors)\n",
    "print(f1_n.shape)\n",
    "plt.subplot(223)\n",
    "lrd.specshow(f1_n, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f1 norm')\n",
    "\n",
    "f2_n = normalize_spectrum_clean(f2, norm_factors)\n",
    "plt.subplot(224)\n",
    "lrd.specshow(f2_n, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f2 norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.power_to_db(np.abs(y_frags_pred[...,0])).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(y_frags_noisy.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.amplitude_to_db(y_frags_noisy[i,...,0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
