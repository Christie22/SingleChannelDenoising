{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising test\n",
    "\n",
    "This script does the same as the denoise command (`denoise.py`):\n",
    " - load audio file\n",
    " - processes it (noise, stft, pre-proc, fragments, normalization)\n",
    " - load a trained model\n",
    " - predict clean speach\n",
    " - unprocess it\n",
    "\n",
    "On top of that, it allows the user to investigate individual fragments, quickly try different parameters, plot and listen to stuff, etc.   \n",
    "It's useful for testing trained model, especially while they're being trained!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/christie/miniconda3/envs/denoising/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import librosa as lr\n",
    "import librosa.display as lrd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from libs.utilities import load_autoencoder_lossfunc, load_autoencoder_model\n",
    "from libs.processing import pink_noise, take_file_as_noise, \\\n",
    "    make_fragments, unmake_fragments_slice , unmake_fragments,\\\n",
    "    s_to_exp, exp_to_s, s_to_reim, reim_to_s, s_to_db, db_to_s,\\\n",
    "    normalize_spectrum, normalize_spectrum_clean, unnormalize_spectrum  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models\n",
    "\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 12:26 phase1bis_s_to_exp(0.167)_1.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 14:34 phase1bis_s_to_exp(0.167)_16.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 13:13 phase1bis_s_to_exp(0.167)_3.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 16:02 phase1bis_s_to_exp(0.167)_32.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 11:50 phase1bis_s_to_exp(1.000)_1.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 14:06 phase1bis_s_to_exp(1.000)_16.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 12:57 phase1bis_s_to_exp(1.000)_3.h5\n",
    "# -rw-rw-r-- 1 christie christie   3965296 May  3 15:34 phase1bis_s_to_exp(1.000)_32.h5\n",
    "# -rw-rw-r-- 1 christie christie   4020592 May  3 12:44 phase1bis_s_to_reim_1.h5\n",
    "# -rw-rw-r-- 1 christie christie   4020592 May  3 15:11 phase1bis_s_to_reim_16.h5\n",
    "# -rw-rw-r-- 1 christie christie   4020592 May  3 13:50 phase1bis_s_to_reim_3.h5\n",
    "# -rw-rw-r-- 1 christie christie   4020592 May  3 16:39 phase1bis_s_to_reim_32.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/riccardo_models/denoising/phase1/phase1bis_s_to_db_3.h5\n"
     ]
    }
   ],
   "source": [
    "type_file = 'train'\n",
    "type_noise = 'pink'\n",
    "snr = 15\n",
    "time_slices = {0:1 ,1:3, 2:16, 3:32}\n",
    "\n",
    "reim_or_exp = 'db' # 'reim', 'exp', 'db'\n",
    "expo = 2.0/3\n",
    "time_slice_ind = 1\n",
    "\n",
    "if reim_or_exp =='reim':\n",
    "    proc_func_name, unproc_func_name = s_to_reim, reim_to_s\n",
    "    proc_func, unproc_func = proc_func_name, unproc_func_name \n",
    "    model_path = '/data/riccardo_models/denoising/phase1/phase1bis_{}_{}.h5'.\\\n",
    "    format(str(proc_func_name).strip('>').split(' ')[1], time_slices[time_slice_ind]) \n",
    "\n",
    "elif reim_or_exp =='exp':\n",
    "    proc_func_name, unproc_func_name = s_to_exp, exp_to_s\n",
    "    proc_func, unproc_func =  proc_func_name(expo), unproc_func_name(expo) \n",
    "\n",
    "    model_path = '/data/riccardo_models/denoising/phase1/phase1bis_{}({:.3f})_{}.h5'.\\\n",
    "    format(str(proc_func_name).strip('>').split('.')[-1][:-1], expo, time_slices[time_slice_ind]) \n",
    "    \n",
    "elif reim_or_exp == 'db':\n",
    "    proc_func_name, unproc_func_name = s_to_db, db_to_s\n",
    "    proc_func, unproc_func = proc_func_name, unproc_func_name  \n",
    "\n",
    "    model_path = '/data/riccardo_models/denoising/phase1/phase1bis_{}_{}.h5'.\\\n",
    "    format(str(proc_func_name).strip('>').split(' ')[1], time_slices[time_slice_ind]) \n",
    "    \n",
    "\n",
    "print(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURATION ###\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'#'0,1,2,3,4'\n",
    "\n",
    "if type_file == 'train':\n",
    "    input_path = '/data/riccardo_datasets/npr_news/ds0/train/NPR_News__03-15-2018_11PM_ET.wav'\n",
    "else:  # test\n",
    "    input_path = '/data/riccardo_datasets/npr_news/test/NPR_News__03-25-2018_11PM_ET.wav'\n",
    "\n",
    "model_name = 'model_example'\n",
    "sr = 16000\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "win_length = 512\n",
    "frag_win_length = 32\n",
    "p_time_slice_args = [0, 0.1, 0.5, 1]\n",
    "\n",
    "time_slice_args = [slice(np.int(frag_win_length//2-p/2*frag_win_length),\\\n",
    "                         np.int(frag_win_length//2+p/2*frag_win_length)) if p!=0 \\\n",
    "                   else slice(np.int(frag_win_length//2), np.int(frag_win_length//2)+1) \\\n",
    "                   for p in p_time_slice_args ]\n",
    "frag_hop_length = 1#time_slices[time_slice_ind]\n",
    "#np.int(frag_win_length * p_time_slice_args[time_slice_ind]) if p_time_slice_args[time_slice_ind]!=0 else 1\n",
    "\n",
    "batch_size = 128\n",
    "normalize = False\n",
    "# noisefile = '/data/riccardo_datasets/demand/NFIELD/ch01.wav' #NFIELD STRAFFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JUNK CODE\n",
    "\n",
    "# p_time_slice_args[time_slice_ind]\n",
    "#frag_hop_length\n",
    "\n",
    "# print(time_slice_args[i].start, time_slice_args[i].stop)\n",
    "\n",
    "# print(frag_win_length.trunc())\n",
    "# str(proc_func_name).strip('>').split(' ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dn] Loading data from /data/riccardo_datasets/npr_news/ds0/train/NPR_News__03-15-2018_11PM_ET.wav...\n",
      "[dn] Generated 3720 fragments with shape (257, 32)\n"
     ]
    }
   ],
   "source": [
    "### INPUT PROCESSING ###\n",
    "\n",
    "print('[dn] Loading data from {}...'.format(input_path))\n",
    "# load data from file name\n",
    "x, _ = lr.load(input_path, sr=sr, duration=30, offset=2)\n",
    "\n",
    "# apply noise!\n",
    "if type_noise == 'pink':\n",
    "    x_noisy = pink_noise(x=x, sr=sr, snr=snr)\n",
    "else:\n",
    "    x_noisy = take_file_as_noise(noisefile)(x=x, sr=sr, snr=snr)\n",
    "\n",
    "# convert to TF-domain\n",
    "s = lr.stft(x_noisy, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "# make fragments\n",
    "s_frags_noisy = make_fragments(s, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length)\n",
    "print('[dn] Generated {} fragments with shape {}'.format(len(s_frags_noisy), s_frags_noisy[0].shape))\n",
    "\n",
    "\n",
    "# apply pre-processing (data representation)\n",
    "y_frags_noisy = proc_func(s_frags_noisy)\n",
    "\n",
    "# normalize fragments\n",
    "y_frags_noisy_n = np.empty((y_frags_noisy.shape))\n",
    "std_frags_noisy = np.empty((len(y_frags_noisy),2))\n",
    "nf_frags_noisy = np.empty((len(y_frags_noisy),2))\n",
    "for i in range(len(y_frags_noisy)):\n",
    "    frag_normalized, frag_norm_factors = normalize_spectrum(y_frags_noisy[i])\n",
    "    y_frags_noisy_n[i] = frag_normalized if normalize else y_frags_noisy[i]\n",
    "nf_frags_noisy[i] = frag_norm_factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dn] Loading model from /data/riccardo_models/denoising/phase1/phase1bis_s_to_db_3.h5...\n",
      "[u] Loading autoencoder model from /data/riccardo_models/denoising/phase1/phase1bis_s_to_db_3.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2002\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2003\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No attr named '\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"' in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2004\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No attr named '_XlaCompile' in name: \"batch_normalization_1/batchnorm/add\"\nop: \"Add\"\ninput: \"batch_normalization_1/moments/Squeeze_1\"\ninput: \"batch_normalization_1/batchnorm/add/y\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d092238ff4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[dn] Loading model from {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_autoencoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# print model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SingleChannelDenoising_source/libs/utilities.py\u001b[0m in \u001b[0;36mload_autoencoder_model\u001b[0;34m(model_path, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mlossfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAEModelFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lossfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lossfunc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0moptimizer_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             optimizer_weight_names = [n.decode('utf8') for n in\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    959\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    961\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clipnorm'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2308\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m     \"\"\"\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 581\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    582\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 581\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    582\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    714\u001b[0m   \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m   return (array_ops.reshape(math_ops.reduce_sum(grad, rx), sx),\n\u001b[0m\u001b[1;32m    717\u001b[0m           array_ops.reshape(math_ops.reduce_sum(grad, ry), sy))\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keep_dims, name, reduction_indices)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(input, reduction_indices, keep_dims, name)\u001b[0m\n\u001b[1;32m   4680\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4681\u001b[0m         \u001b[0;34m\"Sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4682\u001b[0;31m         keep_dims=keep_dims, name=name)\n\u001b[0m\u001b[1;32m   4683\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4684\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    684\u001b[0m       output = pywrap_tensorflow.RunCppShapeInference(\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No shape inference function exists for op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### LOAD TRAINED MODEL ###\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "# model_path = '/data/riccardo_models/denoising/model_tcnk3n8d2_Apr24_e407.h5' # model_tcn2k3n8d2drop00_e4\n",
    "#model_tcn2k3n2d8drop0_Apr25_e131.h5'\n",
    "\n",
    "\n",
    "time_slice = time_slice_args[time_slice_ind]# frag_win_length // 2 #\n",
    "\n",
    "print('[dn] Loading model from {}...'.format(model_path))\n",
    "model, lossfunc = load_autoencoder_model(model_path, time_slice = time_slice)\n",
    "# print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICT DATA ###\n",
    "\n",
    "print('[dn] Predicting with trained model...')\n",
    "y_frags_pred = model.predict(y_frags_noisy)\n",
    "print('[dn] Prediction finished! Generated {} fragments'.format(len(y_frags_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT A FEW PREDICTED FRAGMENTS ###\n",
    "specrange = np.linspace(0, len(y_frags_pred), 10, dtype=int)\n",
    "print(list(specrange))\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "rangespan = len(specrange)\n",
    "j = 1\n",
    "y_frags_pred_dn = np.empty((y_frags_pred.shape))\n",
    "for i in range(len(y_frags_pred)):\n",
    "    # un-normalize (individually)\n",
    "    y_frags_pred_dn[i] = unnormalize_spectrum(y_frags_pred[i], nf_frags_noisy[i]) if normalize else y_frags_pred[i]\n",
    "    if i in specrange:  \n",
    "        if reim_or_exp != 'db':\n",
    "            plt.subplot(2,rangespan,j)\n",
    "            lrd.specshow(lr.amplitude_to_db(y_frags_noisy_n[i,...,0]), vmin=-10, vmax=5, cmap='coolwarm')\n",
    "\n",
    "            plt.subplot(2,rangespan,rangespan+j)\n",
    "            lrd.specshow(lr.amplitude_to_db(y_frags_pred[i,...,0]), vmin=-10, vmax=5, cmap='coolwarm')\n",
    "\n",
    "            j += 1\n",
    "            lrd.specshow(lr.power_to_db(np.abs(y_frags_pred[i,...,0])), cmap='coolwarm')\n",
    "        else:\n",
    "            plt.subplot(2,rangespan,j)\n",
    "            lrd.specshow(y_frags_noisy_n[i,...,0], vmin=-10, vmax=5, cmap='coolwarm')\n",
    "\n",
    "            plt.subplot(2,rangespan,rangespan+j)\n",
    "            lrd.specshow(y_frags_pred[i,...,0], vmin=-10, vmax=5, cmap='coolwarm')\n",
    "\n",
    "            j += 1\n",
    "#             lrd.specshow(np.abs(y_frags_pred[i,...,0]), cmap='coolwarm')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNPROCESS PREDICTED DATA ###\n",
    "\n",
    "# clip negative data\n",
    "#y_frags_pred_dn[y_frags_pred_dn<0]=0\n",
    "\n",
    "# invert data repr : #with or without phase: with or without \", s_frags_noisy\"\n",
    "if reim_or_exp == 'exp' or reim_or_exp =='db':\n",
    "    s_pred = unproc_func(y_frags_pred_dn, s_frags_noisy)\n",
    "else:\n",
    "    s_pred = unproc_func(y_frags_pred_dn)\n",
    "\n",
    "\n",
    "# undo fragments\n",
    "# s_pred = unmake_fragments(s_pred, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length)\n",
    "s_pred = unmake_fragments_slice(s_pred, frag_hop_len=frag_hop_length, frag_win_len=frag_win_length, time_slice=time_slice)\n",
    "\n",
    "# get waveform\n",
    "x_pred = lr.istft(s_pred, hop_length=hop_length, win_length=win_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT RESULT AND LISTEN ###\n",
    "l = lr.time_to_frames(5, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(211)\n",
    "lrd.specshow(lr.amplitude_to_db(np.abs(s[:,:l])), vmin=-50, vmax=25, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.subplot(212)\n",
    "lrd.specshow(lr.amplitude_to_db(np.abs(s_pred[:,:l])), vmin=-50, vmax=25, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(x_pred, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOISY AUDIO ###\n",
    "ipd.Audio(x_noisy, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGINAL AUDIO ###\n",
    "#ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT HISTOGRAMS ###\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.suptitle('Histograms (linear X scale, log Y scale)')\n",
    "\n",
    "## normalized\n",
    "bins = np.linspace(0, 2, 100) #np.logspace(-6, 2, 50)\n",
    "\n",
    "plt.subplot(221)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy_n.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Normalized true (network input)')\n",
    "\n",
    "plt.subplot(222)\n",
    "counts, bins, bars = plt.hist(y_frags_pred.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Normalized pred (network output)')\n",
    "\n",
    "## denormalized\n",
    "bins = np.linspace(0, 2, 100) #np.logspace(-6, 2, 50)\n",
    "\n",
    "plt.subplot(223)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('True (before processing)')\n",
    "\n",
    "plt.subplot(224)\n",
    "counts, bins, bars = plt.hist(y_frags_pred_dn.flatten(), bins=bins)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_ylim(1, 1e9)\n",
    "plt.title('Pred (after processing)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT HISTOGRAMS (LOG SCALE) ###\n",
    "bins = np.logspace(-1, 1, 100)\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.suptitle('Histograms (log X scale, linear Y scale)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "# normalized\n",
    "plt.subplot(221)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy_n.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Normalized true (network input)')\n",
    "\n",
    "plt.subplot(222)\n",
    "counts, bins, bars = plt.hist(y_frags_pred.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Normalized pred (network output)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "# denormalized\n",
    "plt.subplot(223)\n",
    "counts, bins, bars = plt.hist(y_frags_noisy.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('True (before processing)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "plt.subplot(224)\n",
    "counts, bins, bars = plt.hist(y_frags_pred_dn.flatten(), bins=bins, density=True)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_ylim(1, 5)\n",
    "plt.title('Pred (after processing)')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WASTELANDS FROM HERE FORTH ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_frags_noisy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(np.abs(s), np.abs(s_pred))\n",
    "#print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.square(np.abs((y_frags_noisy[...,0]-y_frags_pred[...,0])[...,frag_win_length//2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_frags_noisy.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "\n",
    "x = np.linspace(0,0,128*32) + np.abs(np.random.randn(128*32) * 0.01)\n",
    "f1 = np.reshape(x, (128, 32))\n",
    "plt.subplot(221)\n",
    "lrd.specshow(f1, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f1: mean={:.2f} std={:.2f}'.format(f1.mean(), f1.std()))\n",
    "\n",
    "f2 = np.copy(f1)\n",
    "x = np.abs(np.random.randn(128*16) )\n",
    "f2[:,16:] += np.reshape(x, (128, 16))\n",
    "plt.subplot(222)\n",
    "lrd.specshow(f2, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f2: mean={:.2f} std={:.2f}'.format(f2.mean(), f2.std()))\n",
    "\n",
    "_, norm_factors = normalize_spectrum(np.concatenate([f1, f2], axis=1))\n",
    "f1_n = normalize_spectrum_clean(f1, norm_factors)\n",
    "print(f1_n.shape)\n",
    "plt.subplot(223)\n",
    "lrd.specshow(f1_n, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f1 norm')\n",
    "\n",
    "f2_n = normalize_spectrum_clean(f2, norm_factors)\n",
    "plt.subplot(224)\n",
    "lrd.specshow(f2_n, cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('f2 norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.power_to_db(np.abs(y_frags_pred[...,0])).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(y_frags_noisy.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.amplitude_to_db(y_frags_noisy[i,...,0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
