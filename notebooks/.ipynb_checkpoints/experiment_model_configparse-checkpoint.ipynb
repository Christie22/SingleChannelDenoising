{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/christie/miniconda3/envs/denoising/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import configparser as cp\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TerminateOnNaN, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# custom modules\n",
    "from libs.utilities import load_dataset, create_autoencoder_model\n",
    "from libs.model_utils import LossLayer\n",
    "from libs.data_generator import DataGenerator\n",
    "from libs.processing import pink_noise, s_to_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an ANN autoencoder model\n",
    "\n",
    "def train(model_name, model_configfile,\n",
    "          dataset_path, sr, \n",
    "          rir_path, noise_snrs, \n",
    "          n_fft, hop_length, win_length, frag_hop_length, frag_win_length, \n",
    "          batch_size, epochs, model_path, history_path, force_cacheinit, cuda_device):\n",
    "    print('[t] Training model {} at {} on dataset {}'.format(model_name, model_path, dataset_path))\n",
    "    print('[t] Training parameters: {}'.format({\n",
    "        'epochs': epochs,\n",
    "        'model_path': model_path,\n",
    "        'history_path': history_path,\n",
    "        'cuda_device': cuda_device\n",
    "    }))\n",
    "\n",
    "    # set GPU devices\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "    # load dataset filenames and split in train and validation\n",
    "    print('[t] Splitting data into train and validation subsets 80:20')\n",
    "    filepath_list = load_dataset(dataset_path)\n",
    "    filepath_list_train, filepath_list_valid = train_test_split(\n",
    "        filepath_list, test_size=0.2, random_state=1337)\n",
    "    \n",
    "    # store DataGenerator args\n",
    "    generator_args = {\n",
    "        # dataset cfg\n",
    "        'sr': sr,\n",
    "        'cache_path': None,\n",
    "        # noising/reverberation cfg\n",
    "        'rir_path': rir_path,\n",
    "        'noise_funcs': [pink_noise],  # TODO un-hardcode\n",
    "        'noise_snrs': noise_snrs,\n",
    "        # stft cfg\n",
    "        'n_fft': n_fft,\n",
    "        'hop_length': hop_length,\n",
    "        'win_length': win_length,\n",
    "        # processing cfg\n",
    "        'proc_func': s_to_power,    # TODO un-hardcode\n",
    "        'proc_func_label': s_to_power,    # TODO un-hardcode\n",
    "        # fragmenting cfg\n",
    "        'frag_hop_length': frag_hop_length,\n",
    "        'frag_win_length': frag_win_length,\n",
    "        # general cfg\n",
    "        'shuffle': True,\n",
    "        'label_type': 'clean',\n",
    "        'batch_size': batch_size,\n",
    "        'force_cacheinit': force_cacheinit,\n",
    "    }\n",
    "    print('[t] Data generator parameters: {}'.format(generator_args))\n",
    "\n",
    "    # create DataGenerator objects\n",
    "    training_generator = DataGenerator(filepath_list_train, **generator_args)\n",
    "    validation_generator = DataGenerator(filepath_list_valid, **generator_args)\n",
    "    train_steps_per_epoch = len(training_generator)\n",
    "    valid_steps_per_epoch = len(validation_generator)\n",
    "    print('[t] Train steps per epoch: ', train_steps_per_epoch)\n",
    "    print('[t] Valid steps per epoch: ', valid_steps_per_epoch)\n",
    "\n",
    "    # create model\n",
    "    config = cp.ConfigParser()\n",
    "    config.read(model_configfile)\n",
    "    \n",
    "    model_args = config['DEFAULT']\n",
    "    model_args['input_shape'] = training_generator.data_shape\n",
    "\n",
    "    print('[t] Model factory parameters: {}'.format(model_args))\n",
    "    model, lossfunc = create_autoencoder_model(model_name, model_args)\n",
    "\n",
    "    # compile model (loss function must be set in the model class)\n",
    "    # TODO add metrics https://keras.io/metrics/\n",
    "    model.compile(optimizer='adam', loss=lossfunc)\n",
    "    # print model summaries\n",
    "    model.get_layer('encoder').summary()\n",
    "    model.get_layer('decoder').summary()\n",
    "    model.summary()\n",
    "\n",
    "    # training callback functions\n",
    "    Callbacks = [\n",
    "        # conclude training if no improvement after N epochs\n",
    "        EarlyStopping(monitor='val_loss', patience=8),\n",
    "        # save model after each epoch if improved\n",
    "        ModelCheckpoint(filepath=model_path,\n",
    "                        monitor='val_loss',\n",
    "                        save_best_only=True,\n",
    "                        save_weights_only=False),\n",
    "        TerminateOnNaN(),\n",
    "        # save logs for tensorboard\n",
    "        TensorBoard()\n",
    "        #TrainValTensorBoard(log_dir=logs_dir, write_graph=False)\n",
    "    ]\n",
    "\n",
    "    # train model\n",
    "    print('[t] Begin training process...')\n",
    "    history = model.fit_generator(\n",
    "        generator=training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        validation_steps=valid_steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=Callbacks,\n",
    "        use_multiprocessing=True,\n",
    "        workers=8)\n",
    "\n",
    "    # save training history\n",
    "    # TODO directly plot training history\n",
    "    if history_path is not None:\n",
    "        print('[t] Storing training history to {}...'.format(history_path))\n",
    "        df = pd.DataFrame(history.history)\n",
    "        df.to_pickle(history_path)\n",
    "\n",
    "    # end\n",
    "    print('[t] Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import librosa.display as lrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import IPython.display as ipd\n",
    "# %matplotlib inline\n",
    "\n",
    "import configparser as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = cp.ConfigParser()\n",
    "model_args['DEFAULT'] = {\n",
    "        'kernel_size': 3,\n",
    "        'n_filters': 64,\n",
    "    }\n",
    "\n",
    "with open('example_configfile.txt', 'w') as configfile:\n",
    "    model_args.write(configfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder_model(model_name, config_file_name):\n",
    "    print('[u] Creating autoencoder model from config file{}'.format(config_file_name))\n",
    "    \n",
    "    model_args = cp.ConfigParser()\n",
    "    model_args.read(config_file_name)\n",
    "    \n",
    "    model_args = model_args['DEFAULT']\n",
    "    print(\"model_args['kernel_size']\", type(model_args['kernel_size']))\n",
    "#     print(type(model_args))\n",
    "    \n",
    "#     for key in config['DEFAULT']:\n",
    "#         print(key)\n",
    "#     kernel_size=model_args.pop('kernel_size', '') \n",
    "#     n_filters=model_args.pop('n_filters', '') \n",
    "    # import model factory\n",
    "    \n",
    "    \n",
    "    \n",
    "    if model_name == 'lstm':\n",
    "        return None\n",
    "    elif model_name == 'conv':\n",
    "        return None\n",
    "    else:\n",
    "        print('[u] Importing example model :D')\n",
    "        from models.model_example import AEModelFactory\n",
    "\n",
    "    # calc input shape and enforce it\n",
    "    K.set_image_data_format('channels_last')\n",
    "    # generate model\n",
    "    obj = AEModelFactory(**model_args)\n",
    "    model = obj.get_model()\n",
    "    # return loss function too (TODO: only if there)\n",
    "    return (model, AEModelFactory.get_lossfunc() if True else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u] Creating autoencoder model from config fileexample_configfile.txt\n",
      "model_args['kernel_size'] <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "create_autoencoder_model('lstm','example_configfile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args =  {\n",
    "        'kernel_size': 3,\n",
    "        'n_filters': 64,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args['layers'] = model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(**model_args):\n",
    "    for key in model_args:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size\n",
      "n_filters\n",
      "layers\n"
     ]
    }
   ],
   "source": [
    "extract(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_size': 3, 'n_filters': 64, 'layers': {...}}\n"
     ]
    }
   ],
   "source": [
    "print(model_args['layers']['layers']['layers']['layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args['foo']=model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_size': 3, 'n_filters': 64, 'layers': {...}, 'foo': {...}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    return 1\n",
    "def foo2(x):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(2)\n",
    "u=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('foo(u)')\n",
    "0*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size\n",
      "n_filters\n",
      "layers\n",
      "foo\n",
      "['kernel_size', 'n_filters', 'layers', 'foo']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = []\n",
    "for lay in model_args:\n",
    "    a.append(lay) \n",
    "    print(lay)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel_size' 'n_filters' 'layers' 'foo']\n"
     ]
    }
   ],
   "source": [
    "all_layers = np.array([layer for layer in model_args])\n",
    "print(all_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel_size', 'n_filters', 'layers', 'foo']\n"
     ]
    }
   ],
   "source": [
    "layer_attr = []\n",
    "for attr in model_args:\n",
    "    layer_attr.append(attr)\n",
    "print(layer_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = '4'\n",
    "stride = '4,5'\n",
    "n_filters= '46'\n",
    "layer_names = ['Conv2D','Dense', 'BatchNormalization','Dropout','Conv2DTranspose','Reshape']\n",
    "activation = ['relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "encoder = {}\n",
    "attr = {}\n",
    "attr['stride']=stride\n",
    "attr['n_filters']=n_filters\n",
    "attr['kernel']=kernel\n",
    "n_layers = [4, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ll in range(len(layer_names)):\n",
    "    encoder[layer_names[ll]] = [attr for n in range(n_layers[ll])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['encoder']=encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['decoder']=encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input#, Dense, Conv2D, Conv2DTranspose, \n",
    "#MaxPool2D, BatchNormalization, Flatten, Reshape, Dropout\n",
    "\n",
    "input_shape = 4\n",
    "inputs = 3#Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_layers = np.array([typ for typ in encoder]) #ex: conv, flat, dense\n",
    "type_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_types = type_layers.shape[0]\n",
    "nb_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. layers\n",
      "2. all_attr\n",
      "attr: \n",
      "foo(**attr)(inputs)\n",
      "x: \n",
      "attr: \n",
      "attr: \n",
      "attr: \n",
      "1. layers\n",
      "2. all_attr\n",
      "attr: \n"
     ]
    }
   ],
   "source": [
    "for i in range(nb_types):\n",
    "    layers = type_layers[i]\n",
    "    print('1. layers'.format(layers))\n",
    "    all_attr = encoder[layers]\n",
    "    print('2. all_attr'.format(all_attr))\n",
    "    for ia, attr in enumerate(all_attr):\n",
    "        print('attr: '.format(attr))\n",
    "        #layer_attr = np.array([attr for attr in all_attr])\n",
    "        if i+ia==0: # init\n",
    "            print(type_layers[0]+'(**attr)(inputs)')\n",
    "            x = eval(type_layers[0]+'(0)' )#(**layer_attr)(inputs)\n",
    "            print('x: '.format(x))\n",
    "        else:\n",
    "            x = eval(type_layers[i]+'(0)' )# (**layer_attr)(x)\n",
    "#         x = BatchNormalization()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stride': '4,5', 'n_filters': '46', 'kernel': '4'},\n",
       " {'stride': '4,5', 'n_filters': '46', 'kernel': '4'},\n",
       " {'stride': '4,5', 'n_filters': '46', 'kernel': '4'},\n",
       " {'stride': '4,5', 'n_filters': '46', 'kernel': '4'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder['foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['foo', 'foo2'], dtype='<U4')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4'}\n"
     ]
    }
   ],
   "source": [
    "for e in encoder[layers]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names=['Layer1', 'Layer2','Layer3', 'Layer4','Layer5', 'Layer6','Layer7', 'Layer8']\n",
    "layer_types=['foo', 'foo2','foo', 'foo2','foo', 'foo2','foo', 'foo2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stride': '4,5', 'n_filters': '46', 'kernel': '4'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del attr\n",
    "attr = {}\n",
    "attr['strides']=stride\n",
    "attr['n_filters']=n_filters\n",
    "attr['kernel_size']=kernel\n",
    "attr['activation'] = \n",
    "# attr['type_layer']='foo'\n",
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4'}\n",
      "Layer2\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo'}\n",
      "Layer3\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "Layer4\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo'}\n",
      "Layer5\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "Layer6\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo'}\n",
      "Layer7\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "Layer8\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo'}\n"
     ]
    }
   ],
   "source": [
    "del encoder\n",
    "encoder = {}\n",
    "for ll in range(len(layer_names)):\n",
    "    print(layer_names[ll])\n",
    "    encoder[layer_names[ll]] = attr \n",
    "    print( encoder[layer_names[ll]] )\n",
    "    encoder[layer_names[ll]]['type_layer'] = layer_types[ll]\n",
    "#     print( encoder[layer_names[ll]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder\n",
    "layer_names[ll]\n",
    "encoder[layer_names[ll]]\n",
    "# del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "3. x: \n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "2. attr: \n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n"
     ]
    }
   ],
   "source": [
    "all_layers = np.array([typ for typ in encoder]) #ex: Layer1, Layer2, Layer3\n",
    "# nb_layers = all_layers.shape\n",
    "\n",
    "for i, layer in enumerate(all_layers):\n",
    "    attr = encoder[layer]\n",
    "    print('2. attr: '.format(attr))\n",
    "    print(attr)\n",
    "    type_layer = attr['type_layer']\n",
    "    # print('1. layers'.format(type_layer))\n",
    "#     del attr['type_layer']\n",
    "    if i==0: # init\n",
    "        x = eval(type_layer + '(0)' ) #(**attr)(inputs)\n",
    "        print('3. x: '.format(x))\n",
    "    else:\n",
    "        x = eval(type_layer + '(0)' ) #(**layer_attr)(x)\n",
    "    if type_layer == 'Conv2D': \n",
    "        #calculated each time we compute this special type of layer even though we need only the last occurrence\n",
    "        self.conv_shape = K.int_shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. layers\n",
      "foo\n",
      "2. attr\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n",
      "foo0\n",
      "x: \n",
      "1\n",
      "1. layers\n",
      "foo2\n",
      "2. attr\n",
      "{'stride': '4,5', 'n_filters': '46', 'kernel': '4', 'type_layer': 'foo2'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(nb_types):\n",
    "    layers = type_layers[i]\n",
    "    print('1. layers'.format(layers))\n",
    "    print(layers)\n",
    "    attr = encoder[layer]\n",
    "    print('2. attr'.format(attr))\n",
    "    print(attr)\n",
    "        #layer_attr = np.array([attr for attr in all_attr])\n",
    "    if i==0: # init\n",
    "        print(type_layers[i]+'0') #\n",
    "        x = eval(type_layers[i]+'(0)' )#(**layer_attr)(inputs)\n",
    "#         print('x: '.format(x))\n",
    "        print(x)\n",
    "    else:\n",
    "        x = eval(type_layers[i]+'(0)' )# (**layer_attr)(x)\n",
    "#     x = foo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Layer8'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = cp.ConfigParser()\n",
    "model_args['model_args'] = {\n",
    "        'encoder': encoder,\n",
    "        'decoder': encoder,\n",
    "    }\n",
    "with open('example_configfile.txt', 'w') as configfile:\n",
    "    model_args.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u] Creating autoencoder model from config fileexample_configfile.txt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-766ce7406ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_autoencoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'example_configfile.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-047818cc867d>\u001b[0m in \u001b[0;36mcreate_autoencoder_model\u001b[0;34m(model_name, config_file_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DEFAULT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_args['kernel_size']\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     print(type(model_args))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/denoising/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kernel_size'"
     ]
    }
   ],
   "source": [
    "create_autoencoder_model('lstm','example_configfile.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
