# Literature brainstorming
> Notes from 1st group meeting

## Roadmap (ideas)

### Applications
- Denoising
- Dereverberation

### Data representation
Ways of inputting the data into the network
- Time-domain
- T-F domain (i.e. STFT)
  - Log-Mel spectrogram
  - Cochleogram
  - Re/Im spectrogram
  - MFCC
  - GFCC (gammatone)
- Other features
  - T60

### Targets
This is what the network tries to estimate:
- Masks (IBM, IRM, etc)
- Spectral mapping (i.e., estimate clean speech spectrogram)

### Metrics
Evaluates how the system performs:
- SDR (source-to-distortion ratio)
- SAR (source-to-artifact ratio) 
- SIR (source-to- interference ratio)
- STOI
- Cortana ASR, HTK, or similar speech recognition software

### Architecture
- Autoencoders (denoising, variational, deep, etc)
- LSTM

### Datasets
- TO BE DISCUSSED

### Refs
- Dereverberation
  - [57] K. Han, Y. Wang, and D.L. Wang, "Learning spectral mapping for speech dereverebaration," in Proceedings of ICASSP, pp. 4661-4665, 2014.
  - [58] K. Han, et al., "Learning spectral mapping for speech dereverberation and denoising," IEEE/ACM Trans. Audio Speech Lang. Proc., vol. 23, pp. 982-992, 2015.
  - [190] B. Wu, K. Li, M. Yang, and C.-H. Lee, "A reverberation-time-aware approach to speech dereverberation based on deep neural networks," IEEE/ACM Trans. Audio Speech Lang. Proc., vol. 25, pp. 102-111, 2017.
  - [211] Y. Zhao, Z.-Q. Wang, and D.L. Wang, "A two-stage algorithm for noisy and reverberant speech enhancement," in Proceedings of ICASSP, pp. 5580-5584, 2017.
- Denoising
  - [116] X. Lu, Y. Tsao, S. Matsuda, and C. Hori, "Speech enhancement based on deep denoising autoencoder," in Proceedings of Interspeech, pp. 555-559, 2013.
- LSTMs
  - Single-Channel Speech Enhancement using Deep Learning, Hulser, 2018
  - PHASE-SENSITIVE AND RECOGNITION-BOOSTED SPEECH SEPARATION USING DEEP RECURRENT NEURAL NETWORKS, 2015, Erdogan
  - A NOVEL APPROACH FOR AUTOMATIC ACOUSTIC NOVELTY DETECTION USING A DENOISING AUTOENCODER WITH BIDIRECTIONAL LSTM NEURAL NETWORKS, 2015, Marchi
  - Discriminatively Trained Recurrent Neural Networks for Single-Channel Speech Separation, Weninger, 2014

## Iteration #1
- Application: denoising
- Data representation: spectral mapping [116][196][57][197]
- Target: Spectral mapping (synthesize speech from spectrogram)
- Metrics: SDR, STOI
- Architecture: Denoising AE
- Datasets: N/A