# Let's train some models
> semester project group meeting 11/04

## Agenda
- Progresses (exp time: ~10)
  - `C` Implementation
    - model designer
    - flexible loss function with custom window
  - `R` Research
    - some audible results (hsu, lstm models)
    - no computational bottleneck on gpu
    - briefly experimented with loss funcs
    - 16-bit operations: not suitable for builtin batch norm
  - Other
    - got noise dataset from company
    - no progress on report

- `C` Roadmap (exp time: ~15)
  - Research
    - thoroughly test normalization!
    - investigate novel ML technologies (e.g. attention layers, TCN, etc)
    - test performances of models
  - Implementation
    - design relevant models
    - fix metrics/results scripts
    - improvements on framework (i.e. scripts parametrization)
    - real-time demo of some sort
  - Other
    - try real-world noise (fix noising functions first)
    - write report

- Challenges/Questions (exp time: til end of meeting)
  - `C` no exhaustive description of model architecture in the literature
  - `C` training plateaus after few generations
  - `C` normalization (0-mean, 1-std) on power spectrograms
  - `R` GPU memory maxes out easily
  - `R` lack of final validation dataset

