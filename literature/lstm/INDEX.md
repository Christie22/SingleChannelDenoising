# Literature
> Papers on LSTM applied to audio

- `[GHu2018]` Single-Channel Speech Enhancement using Deep Learning
- `[HEr2015]` Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks
- `[EMa2015]` A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks
- `[FWe2014]` Discriminatively trained recurrent neural networks for single-channel speech separation

Other resources:
- http://slazebni.cs.illinois.edu/spring17/lec26_audio.pdf
-

## `[GHu2018]`
- Data representation:
- Target:
- Metrics/Loss:
- Architecture:
- Training:
- Dataset:
- Baseline:
- Evaluation:
- Notes:
- Useful refs:

## `[HEr2015]`
- Data representation:
- Target: phase-sensitive mask
- Metrics/Loss: phase-sensitive spectrum approximation
- Architecture: bidirectional LSTM
- Training: multi-stage training, adding layers
- Dataset: CHiME-2
- Baseline: 2 lstm layers, 256 nodes, 100 bin log-mel spectogram
- Evaluation: SDR, SIR
- Notes: good baseline!
- Useful refs:

## `[EMa2015]`
- Data representation:
- Target:
- Metrics/Loss:
- Architecture:
- Training:
- Dataset:
- Baseline:
- Evaluation:
- Notes:
- Useful refs:

## `[FWe2014]`
- Data representation:
- Target:
- Metrics/Loss:
- Architecture:
- Training:
- Dataset:
- Baseline:
- Evaluation:
- Notes:
- Useful refs:
